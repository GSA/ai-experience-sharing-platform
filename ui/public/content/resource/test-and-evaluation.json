{"date":"2020-07-22T21:19:13.392Z","title":"Test and Evaluation","fields":[{"key":"category","title":"Category","value":"processes"},{"key":"tags","title":"Tags","value":"AI Development Process"}],"body":"Though some agencies, notably those in the defense and intelligence community, emphasize testing and evaluating software, due to the nature of AI development and deployment, all AI projects should place additional importance on test and evaluation. Very public examples of AI gone wrong highlight that the responsibility principles explained above are a critical part of the AI landscape. Many of these challenges can be addressed with a dedicated test and evaluation process.\n\nThe fundamental purpose of Test & Evaluation (T&E) is to provide knowledge to assist in risk management that’s involved in developing, producing, operating, and sustaining systems and capabilities. T&E provides knowledge of system capabilities and limitations for use in improving the system performance and optimizing system use and sustainment in operations. T&E provides information on limitations (technical or operational), Critical Operational Issues (COI), of the system under development so that they can be resolved prior to production and deployment.\nTraditional systems usually undergo two distinct stages of test and evaluation. First is developmental test and evaluation (DT&E), which verifies that a system meets technical performance specifications. DT&E often makes use of models, simulations, test beds and prototypes to test components and subsystems, hardware and software integration, and production qualification.  Usually, this type of testing is performed largely by the system developer.\n\nDT&E usually identifies a number of issues that need fixing, and, in time, is followed by operational test and evaluation (OT&E). At this stage, the system is usually tested under realistic operational conditions, and the operator is involved. It is in this step that we learn about the system’s mission effectiveness, suitability, and survivability.\n\nSome aspects of T&E of AI-enabled systems are quite similar to their analogues in other software-intensive systems, but there are also several changes in the science and practice of T&E that have been introduced with AI. Some AI-enabled systems present challenges in what to test, and how and where to test it; all of those are, of course, project-dependent. At a high level, however, T&E of AI-enabled systems are part of the continuous DevSecOps cycle (pictured below), or an Agile development process. Regardless of the process, the goal of T&E becomes continuous testing and monitoring that provides timely feedback to developers from various stages of the product: on the code level (unit testing), at the integration level (system testing, security and adversarial testing), and at the operator level (user testing).\n\nThese assessments include the definition of requirements and metrics through conversations with various stakeholders, design of experiments and tests, and analysis and actionable recommendations to the leadership on overall system performance across its operational envelope.\n","name":"test-and-evaluation","path":"/resource/test-and-evaluation","excerpt":"Though some agencies, notably those in the defense and intelligence community, emphasize testing and evaluating software, due to the nature of AI development and deployment, all AI projects should place additional importance on test and evaluation. Very public examples of AI gone wrong highlight that the responsibility principles explained above are a critical part of the AI landscape. Many of these challenges can be addressed with a dedicated test and evaluation process.","toc":[]}