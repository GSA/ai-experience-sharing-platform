{"date":"2020-07-22T21:14:32.570Z","title":"Governance","fields":[{"key":"category","title":"Category","value":"processes"},{"key":"tags","title":"Tags","value":"AI Development Process"}],"body":"## [](#data-governance)[](#data-governance)[](#data-governance)[](#data-governance)[](#data-governance)Data governance\n\nData is central to the identification of AI use cases and development of AI applications.\\\\\nEmerging data governance models for the Federal government are being driven by the Evidence and OPEN Acts.  Federal agencies are standing up Data Governance Bodies led by Chief Data Officers (CDO’s), who participate in the U.S. federal government’s  CDO Council.  The intention of this process is to standardize data collection and storage and improve accessibility for everyone.  The graphic below demonstrates how this cyclical process helps to bring about AI-readiness for the Federal government and to promote innovation in the private sector. Key concepts include:\n\n-   Data Standardization. This is referring to how agencies can best organize and manage data to foster opportunities for using data as a strategic asset.\n-   Data Sharing. This is referring to the internal sharing of data within government agencies and between agencies.\n-   Data Release. This refers to how the Federal government can release data to outside organizations in the private sector and drive innovation that benefits all Americans.\n\nThis process is driven by the Federal Data Strategy, which articulates a Mission Statement, 10 Principles, and 40 Practices.  These can be found in the final form in the Office of Management and Budget (OMB) Memorandum M-19-18.  Additional detail regarding their deployment can be found at strategy.data.gov. A document titled A Playbook in Support of the Federal Data Strategy is available to help agencies implement the strategy by improving their organizational leadership, prioritizing data governance, and assessing maturity for leveraging data as a strategic asset.  The playbook describes these efforts as follows:\n\n“Data plays an increasingly important role in our modern world and new approaches to gathering, analyzing and using data are transforming the way federal agencies fulfill their missions and serve the nation. Maintaining trust in federal data is also pivotal to a democratic process. This expansion in data use also poses challenges for how agencies execute data-related activities as each agency faces a different set of infrastructure challenges, abides by different mission parameters, and maintains a unique culture. In this evolving environment, working with data and data management have become disciplines key to organizational success. … The Federal Data Strategy supports a coordinated approach to federal data leadership, including data use and management to help agencies deliver on the promise of data in the 21st century. By helping agencies establish more consistent and integrated data infrastructure and data practices, the Strategy seeks to move the Federal Government toward fully leveraging data as a strategic asset, including supporting strong data governance and providing the data protection and security that the American people deserve.”\n\nAdditional resources on data maturity models can be found in the Appendix.\n\n## [](#ai-governance)[](#ai-governance)[](#ai-governance)[](#ai-governance)[](#ai-governance)AI governance\n\nAI governance is the structure and process that helps to ensure that an organization’s AI related activities are being conducted in a legal, responsible, and policy-driven way.  Good AI governance helps ensure an agency is able to deliver mission-critical AI capabilities, mitigate associated risks, and demonstrate net-positive benefits of the applications in use.  \n\nBecause AI governance is an evolving field of practice for both the private sector and the U.S. Government, the discussion of this topic in this guide is not meant to be conclusive or prescriptive.  The goal is to provide examples of concepts relevant to AI governance, along with emerging perspectives that may aid agencies in responsibly achieving their missions.\n\n### [](#ai-principles)[](#ai-principles)[](#ai-principles)[](#ai-principles)[](#ai-principles)AI Principles\n\nAs a foundational AI principle, we can think of responsible AI as a high level concept that implies taking precautions to evaluate and mitigate possible risks prior to proceeding with the development of an AI solution.  The conceptual areas within responsible AI that require the most attention can be organized into the four categories of accountability, explainability, fairness, and ethics. Not all AI applications will need to be examined through the lens of all four categories, but almost all AI applications will cross into the territory of at least one or more.     \n\nDifferent Federal agencies will ultimately need to identify and address their own considerations in regard to AI principles.  Such principles can be enumerated in an AI Policy Statement as discussed in the next section.\n\n### [](#ai-policy-statement-overview)[](#ai-policy-statement-overview)[](#ai-policy-statement-overview)[](#ai-policy-statement-overview)[](#ai-policy-statement-overview)AI Policy Statement overview\n\nLeading technology organizations and many governments around the world have adopted an AI Policy Statement or a statement of AI Principles.  While a statement of AI Principles is likely to be a higher level set of guiding ideas, an AI Policy Statement can be more specific to a mission area or even a single AI application.  Even more granular elements of risk and mitigation can be addressed by individual AI Project Charters when appropriate for a given AI project.  The core components of an AI Policy Statement may often include the following:\n\n-   The organization's purpose in developing and deploying AI applications and a commitment to doing so responsibly.\n-   An outline of accountability measures, including legal and technical safeguards that ensure that models will perform consistently with their objectives and can be quickly deactivated if necessary.\n-   A discussion of which types of data, algorithms, and models will likely be used and how well the mathematical processes and resulting trade-offs may lend themselves to explainability for users.\n-   In what way any competing definitions of fairness for different groups are being addressed.\n-   A description of identifiable risks and mitigation measures for specific types of AI applications.\n-   A description of mechanisms for auditing algorithms for bias and opportunities for participation and feedback by parties and groups that may be impacted.\n-   An examination of the relevant questions of ethics, whether the AI applications are consistent with broadly accepted values and a demonstration that the results will produce benefits that substantially outweigh the risks.\n\nMost of the questions around risk mitigation measures that an AI Policy Statement may cover are not necessarily new and existing accountability and ethics frameworks should be drawn upon.  The new and unique challenges presented by AI, however, do call for a thoughtful consideration of how to apply existing principles in new settings and unique combinations.\n\nA complete template for an AI Policy Statement can be found in the Appendix.  A more detailed discussion of AI principles can be found in the Responsible AI section further down in this guide.\n","name":"governance","path":"/resource/governance","excerpt":"Data is central to the identification of AI use cases and development of AI applications.","toc":[{"text":"Data governance","url":"#data-governance"},{"text":"AI governance","url":"#ai-governance"},{"text":"AI Principles","url":"#ai-principles"},{"text":"AI Policy Statement overview","url":"#ai-policy-statement-overview"}]}